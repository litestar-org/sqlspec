---
description:
globs:
alwaysApply: true
---
# SQL Authoring and Management
<!-- alwaysApply: true -->

## Objective
To ensure SQL used within the project is correct, maintainable, efficient, and compatible with supported database dialects, leveraging `sqlglot` for parsing and dialect operations, and a robust, configurable single-pass processing pipeline.

## Context
- The `sqlspec` library interacts with various SQL databases and involves authoring, parsing, transforming, validating, and processing SQL statements.
- `sqlglot` is a key tool for SQL dialect validation, conversion, and expression tree manipulation.
- A core architectural principle is the single-pass processing pipeline (`StatementPipeline`, `SQLProcessingContext`) to ensure efficiency and consistency.
- `SQLConfig` plays a vital role in configuring this pipeline.

## Rules

### 1. SQL Dialect Awareness and `sqlglot` Usage
<!-- alwaysApply: true -->
- **`sqlglot` for Parsing and Manipulation**: Utilize `sqlglot` for all SQL parsing into expression trees, dialect-specific rendering, and complex transformations.
- **Dialect Specification**: Always be explicit about the target SQL dialect when using `sqlglot` functions for parsing or generation if ambiguity exists.
- **Clarity**: SQL code, whether in `.sql` files or embedded in Python strings, should be clear, readable, and well-formatted.
- **Parameterization**: Always use parameterized queries. The `sqlspec` library's `SQL` object and driver interfaces manage parameterization for execution. Direct construction of SQL with unescaped variable input is PROHIBITED.
- **Prioritize Programmatic AST Manipulation**: When constructing or modifying SQL queries programmatically, especially those with dynamic structures (e.g., conditional clauses, dynamic column/table names), **strongly prefer using `sqlglot`'s expression API (e.g., `sqlglot.exp.Column()`, `sqlglot.exp.Table()`, `sqlglot.exp.Where()`, etc.) over string concatenation or formatting.** Manipulating the AST directly ensures syntactic correctness, better dialect compatibility, and reduces the risk of SQL injection vulnerabilities that can arise from manual string construction. This approach aligns with `sqlglot`'s core strength as an AST toolkit.
- **Stay Current with `sqlglot` Evolution**: `sqlglot` is an actively developed library with frequent updates to its API, dialect support, and optimization capabilities. When implementing complex SQL transformations, relying on specific dialect features, or extending `sqlglot`'s functionality, **refer to the official `sqlglot` GitHub repository, particularly its `CHANGELOG.md` and recent commit history.** This practice will help in leveraging the latest features, understanding any API changes, and ensuring that our usage remains robust and efficient.

### 2. Embedded SQL in Python
<!-- alwaysApply: true -->
- **Readability**: For complex SQL queries embedded in Python, use multi-line strings with appropriate indentation. Consider dedicated SQL files for very large queries.
- **No Dynamic String Formatting for SQL Structure**: Do not use Python string formatting (f-strings, `.format()`) to construct the *structure* of SQL queries with variable table names, column names, or SQL keywords. Use `sqlglot` expression APIs for programmatic construction if dynamic structure is unavoidable.

### 3. Internal SQL Abstractions (for `sqlspec` contributors)
<!-- alwaysApply: true -->
- **`SQL` Object**: The `sqlspec.statement.sql.SQL` class is the primary abstraction for representing SQL statements and their parameters. All SQL to be executed via `sqlspec` drivers MUST be encapsulated in an `SQL` object.
- **Builder Patterns**: When programmatic SQL construction is necessary, utilize the builder patterns provided within `sqlspec.statement.builder` (e.g., `SelectBuilder`, `InsertBuilder`). These builders should produce `sqlglot` expressions or `SQL` objects.
- **Consistency**: Adhere to existing patterns and abstractions for SQL statement construction, processing, and execution as defined by the `SQL` class and the statement processing pipeline.

### 4. Single-Pass Pipeline Architecture (UNBREAKABLE RULE)
<!-- alwaysApply: true -->
- **Parse Once, Transform Once, Validate/Analyze Once**: All SQL processing within `sqlspec` (from raw SQL/expression to ready-for-driver form) MUST adhere to a single-pass pipeline. No redundant parsing, multiple transformation loops, or repeated validation/analysis of the same logical statement is allowed unless an explicit, documented exception for a highly specific, unavoidable scenario is approved.
- **Mandatory Architecture**: All SQL processing MUST go through the `StatementPipeline` and `SQLProcessingContext` architecture. This is initiated by the `SQL` object's internal `_ensure_processed()` method.
    - **`SQLProcessingContext`**: This context object carries the SQL expression, parameters, configuration, and other relevant data through the pipeline. While it can be modified by processors, these modifications should be clearly defined by each processor. The goal is a predictable flow of state.
    - **`StatementPipeline`**: Executes a sequence of processors (validators, transformers, analyzers) on the `SQLProcessingContext`.
- **Pipeline Output**: The `StatementPipeline.execute_pipeline` method MUST return a comprehensive result object encapsulating:
    - The final transformed `sqlglot.Expression`.
    - The final merged parameters and detailed `ParameterInfo`.
    - A consolidated list/dictionary of all issues (errors, warnings, info messages) from all processors.
    - The `StatementAnalysis` result.
    This result is then cached by the `SQL` object.
- **Early Exit / Short-Circuiting**: The `StatementPipeline` SHOULD support optional short-circuiting. If a processor reports a critical, unrecoverable error, the pipeline may halt further processing to save resources, even if `SQLConfig.strict_mode` is off. The pipeline result must indicate such an early exit.

### 5. Pipeline Configuration and Processors (MANDATORY)
<!-- alwaysApply: true -->
- **Declarative Pipeline Definition in `SQLConfig`**: `SQLConfig` MUST support declarative definition of statement processing pipelines. This includes specifying lists of processor *classes* or unique string identifiers/names for transformers, validators, and analyzers. The `StatementPipeline` (or `SQLConfig.get_statement_pipeline()`) is responsible for instantiating these processors.
    - *Benefit*: Facilitates easier configuration, reduces risk of state sharing from reused processor instances, and allows conditional enabling/disabling.
- **Granular Control in `SQLConfig`**: `SQLConfig` SHOULD allow fine-grained control over which individual processors (from defaults or custom lists) run or are excluded for a particular `SQL` object or configuration profile.
- **Conditional Execution of Processors**: The pipeline architecture SHOULD support mechanisms for processors to declare prerequisites or for the pipeline to conditionally skip processors based on the `SQLProcessingContext` state (e.g., skip a complex validator if a basic syntax error was already found).
- **`ProcessorProtocol` Clarity**: The `ProcessorProtocol` (and any specific sub-protocols for transformers, validators, analyzers) MUST have clear contracts regarding:
    - What parts of the `SQLProcessingContext` they read.
    - What parts of the `SQLProcessingContext` they may modify (if any).
    - What explicit outputs they produce.
    Processors should ideally be stateless or manage state very carefully if unavoidable.

### 6. Pipeline Component Evaluation and Consolidation (MANDATORY)
<!-- alwaysApply: true -->
- **Review Existing Components**: Before adding or modifying logic in pipeline processors (validators, transformers, analyzers), always review all existing components.
- **No Duplication (DRY)**: NEVER duplicate logic already present in another processor. If similar functionality is needed, refactor or generalize the existing component, or create a new, more focused reusable component.
- **Consolidation and Improvement**: Actively seek opportunities to consolidate, improve efficiency, or enhance the clarity of existing pipeline components. Document these suggestions and strive for a unified, maintainable pipeline.
- **Testability**: Individual pipeline processors MUST be designed for easy unit testing in isolation. This requires that `SQLProcessingContext` can be easily mocked or constructed for test scenarios.

### 7. Testing SQL Logic (MANDATORY)
<!-- alwaysApply: true -->
- **Comprehensive Coverage**: All SQL parsing, transformation, validation, and generation logic MUST be covered by parameterized tests.
- **Edge Cases and Dialects**: Tests must include edge case scenarios and validation against all supported SQL dialects for dialect-sensitive operations.
- **Parameterization Styles**: Test integration with driver protocols for all supported dialects and parameterization styles (e.g., qmark, numeric, format, pyformat).

## Cross-References
- See `.cursor/rules/sql/01_sql_class_implementation.mdc` for `SQL` object internal architecture.
- See `.cursor/rules/core/01_code_structure_style.mdc` for general single-pass architecture rules.
- See `.cursor/rules/adapters/00_adapter_development.mdc` for adapter integration with the pipeline.

## Exceptions
- SQL snippets used purely for illustrative purposes in documentation or simple tests might not require full pipeline processing if their context is self-contained and limited.
